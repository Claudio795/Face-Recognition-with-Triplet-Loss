{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LFWDataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDqfRldZSDds"
      },
      "source": [
        "# IA Project - Face Recognition with Dynamic Triplet Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74ceGeGASHIC"
      },
      "source": [
        "References: https://openaccess.thecvf.com/content_ICCV_2019/papers/Zhang_Learning_Local_Descriptors_With_a_CDF-Based_Dynamic_Soft_Margin_ICCV_2019_paper.pdf\n",
        "\n",
        "Dataset: http://vis-www.cs.umass.edu/lfw/#download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhRpOYJZR_ne"
      },
      "source": [
        "import torch\n",
        "from matplotlib import pyplot as plt\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms.functional as TF\n",
        "import torchvision.transforms as T\n",
        "import numpy as np\n",
        "import collections\n",
        "import PIL.Image\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import os\n",
        "import random\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKIejUZSSJq8",
        "outputId": "f49cccb5-224e-4462-e973-e6b0ea16588f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(dev)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkFSjhnQSLt7"
      },
      "source": [
        "### Pre-precessing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdSQ4aNRSNyr"
      },
      "source": [
        "#path\n",
        "data_path = \"./LFW_DIR\"\n",
        "train_path = \"./data/train_pairs.txt\"\n",
        "test_path = \"./data/test_pairs.txt\"\n",
        "people_path = \"./data/people.txt\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywc2QkEkvM2c"
      },
      "source": [
        "norm_mean = (0.485, 0.456, 0.406)\n",
        "norm_std = (0.229, 0.224, 0.225)\n",
        "\n",
        "test_transform = T.Compose([\n",
        "    T.Resize(250),  # make 250x250\n",
        "    T.CenterCrop(150),   # then take 150x150 center crop\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(norm_mean, norm_std),\n",
        "])\n",
        "\n",
        "train_transform = T.Compose([\n",
        "    T.Resize(250),\n",
        "    T.RandomCrop(150),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(norm_mean, norm_std),\n",
        "])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73VKzt_sSO87"
      },
      "source": [
        "def readPeople(people_path):\n",
        "  people_list = []\n",
        "  with open(people_path, 'r') as file:\n",
        "    for line in file.readlines():\n",
        "      person = line.strip().split()\n",
        "      people_list.append(person)\n",
        "  return people_list"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPQxtfRlTTgd"
      },
      "source": [
        "people_list= readPeople(people_path)\n",
        "# people_list"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgSGZx3JadkX"
      },
      "source": [
        "# cambiare i nomi con le labels\n",
        "def getLabeledImages(data_path, people_list):\n",
        "  labeledImages = {}\n",
        "  label = 0\n",
        "  \n",
        "\n",
        "  for person in people_list:\n",
        "    if int(person[1]) > 1:    # se ho piÃ¹ di una immagine per persona\n",
        "      for img_id in range(1, int(person[1])+1):\n",
        "        path = os.path.join(data_path, person[0], person[0] + '_' + '%04d' % img_id + '.jpg')\n",
        "        labeledImages[path] = label\n",
        "      label += 1\n",
        "\n",
        "  return labeledImages"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxHovEu-U9rt",
        "outputId": "e49c25ca-a64b-4aa8-ccb1-a9ef2c954aad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "labeledImages = getLabeledImages(data_path, people_list)\n",
        "print(len(labeledImages.keys()))    # dizionario 'img_path: label'\n",
        "print(len(set(labeledImages.values())))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9164\n",
            "1680\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JIPlIw7FfBg"
      },
      "source": [
        "class LFWDataset(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self, labeledImages, transform=None):\n",
        "    self.transform = transform\n",
        "    self.labeledImages = labeledImages\n",
        "    self.images = list(labeledImages.keys())\n",
        "    # self.indeces = indeces\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    anchor_path = self.images[index]\n",
        "    anchor_label = self.labeledImages[anchor_path]\n",
        "    anchor_img = PIL.Image.open(anchor_path)\n",
        "\n",
        "    # get positive image path\n",
        "    positive_list = [item for item in self.images if self.labeledImages[item] == anchor_label and item != anchor_path]\n",
        "    positive_path = random.choice(positive_list)\n",
        "\n",
        "    # get negative image path\n",
        "    negative_list = [item for item in self.labeledImages.keys() if item not in positive_list]\n",
        "    negative_path = random.choice(negative_list)\n",
        "\n",
        "    # get images from paths\n",
        "    positive_img = PIL.Image.open(positive_path)\n",
        "    negative_img = PIL.Image.open(negative_path)\n",
        "\n",
        "    # transform images\n",
        "    if self.transform:\n",
        "      anchor_img = self.transform(anchor_img)\n",
        "      positive_img = self.transform(positive_img)\n",
        "      negative_img = self.transform(negative_img)\n",
        "\n",
        "    return anchor_img, positive_img, negative_img, anchor_label"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRDiltBqf_Zj"
      },
      "source": [
        "lfw_dataset = LFWDataset(labeledImages)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpDxICRVGLeQ",
        "outputId": "a7743bd3-ee2a-446c-9581-b3d0cf716b54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Compute dataset sizes\n",
        "num_data = len(lfw_dataset)\n",
        "print(f\"Num. samples: {num_data}\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num. samples: 9164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5J_rCfiGUQ4"
      },
      "source": [
        "# List of indexes on the dataset\n",
        "list_idx = list(range(num_data))\n",
        "random.shuffle(list_idx)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hKL7O-wwwbK"
      },
      "source": [
        "#test fraction\n",
        "test_frac = 0.1\n",
        "# Compute number of samples\n",
        "num_test = int(num_data*test_frac)\n",
        "num_data = num_data - num_test\n",
        "# Split set\n",
        "test_idx = list_idx[num_data:]\n",
        "list_idx = list_idx[:num_data]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiWIKg3MGf1u"
      },
      "source": [
        "# Split \n",
        "test_dataset = Subset(lfw_dataset, test_idx)\n",
        "dataset = Subset(lfw_dataset, list_idx)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHOgvL_uGJvZ"
      },
      "source": [
        "#validation fraction\n",
        "val_frac = 0.1\n",
        "# Compute number of samples\n",
        "num_val = int(num_data*val_frac)\n",
        "num_data = num_data - num_val\n",
        "# Split set\n",
        "val_idx = list_idx[num_data:]\n",
        "list_idx = list_idx[:num_data]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZuNH2ycGrhS"
      },
      "source": [
        "# Split train_dataset into training and validation\n",
        "val_dataset = Subset(lfw_dataset, val_idx)\n",
        "train_dataset = Subset(lfw_dataset, list_idx)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Sg_0SpRcUay"
      },
      "source": [
        "train_dataset.dataset.transform = train_transform\n",
        "test_dataset.dataset.transform = test_transform\n",
        "val_dataset.dataset.transform = test_transform"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qX1XMKn-HaUH",
        "outputId": "ffb7ebac-a3fb-429a-b322-01d42a735871",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "num_train = len(train_dataset)\n",
        "num_test = len(test_dataset)\n",
        "num_val = len(val_dataset)\n",
        "\n",
        "print(f\"Num. training samples: {num_train}\")\n",
        "print(f\"Num. test samples: {num_test}\")\n",
        "print(f\"Num. val samples: {num_val}\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num. training samples: 7424\n",
            "Num. test samples: 916\n",
            "Num. val samples: 824\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpX2l2-cGugC"
      },
      "source": [
        "# Define loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, num_workers=4, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=64, num_workers=4, shuffle=False)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=64, num_workers=4, shuffle=False)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y02ZlSDbG6ur"
      },
      "source": [
        "# Define dictionary of loaders\n",
        "loaders = {\"train\": train_loader,\n",
        "           \"val\": val_loader,\n",
        "           \"test\": test_loader}"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5az1HtKhHAXJ"
      },
      "source": [
        "### Dynamic Triplet Loss implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_u9gNzvG8bu"
      },
      "source": [
        "class TripletLoss(nn.Module):\n",
        "  def __init__(self, margin = 0.2):\n",
        "    super(TripletLoss, self).__init__()\n",
        "    self.margin = margin\n",
        "\n",
        "  def pairwise_dist(x, y):\n",
        "    dist = torch.sqrt((x - y).pow(2).sum(1))\n",
        "    return dist\n",
        "\n",
        "  def forward(self, anchor, positive, negative):\n",
        "    margin = self.margin\n",
        "    pos_dist = pairwise_dist(anchor, positive)\n",
        "    print(pos_dist, pos_dist.shape)\n",
        "    neg_dist = pairwise_dist(anchor, negative)\n",
        "    print(neg_dist)\n",
        "    loss = pos_dist - neg_dist + margin\n",
        "    loss = torch.clamp(loss, min = 0.0).sum\n",
        "    return loss"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5O85S5HHQ0q"
      },
      "source": [
        "### CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rStJHLI-jPmk",
        "outputId": "8beb0924-cdc4-4309-8b57-0dea622c71fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(set(labeledImages.values()))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1680"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4pIACoM8nGj"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 150, kernel_size=5, padding=0, stride=1),\n",
        "            nn.PReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.BatchNorm2d(150),\n",
        "            # nn.Dropout(0.3),\n",
        "\n",
        "            nn.Conv2d(150, 256, kernel_size=5, padding=0, stride=1),\n",
        "            nn.PReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            # nn.Dropout(0.3)\n",
        "          \n",
        "            nn.Conv2d(256, 256, kernel_size=5, padding=0, stride=1),\n",
        "            nn.PReLU(),\n",
        "            nn.MaxPool2d(kernel_size=4, stride=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            # nn.Dropout(0.3)\n",
        "\n",
        "            nn.Conv2d(256, 512, kernel_size=5, padding=0, stride=1),\n",
        "            nn.PReLU(),\n",
        "            nn.MaxPool2d(kernel_size=4, stride=2),\n",
        "            nn.BatchNorm2d(512),\n",
        "            # nn.Dropout(0.3)\n",
        "        )\n",
        "  \n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(8192, 4096),\n",
        "            nn.PReLU(),\n",
        "            nn.Linear(4096, 1680)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc_layers(x)\n",
        "        return x"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j62LjC9ffCCl",
        "outputId": "5ab7df43-2bc8-4481-fb9f-9b256092fdd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Create the model\n",
        "model = CNN()\n",
        "# Get input\n",
        "test_x = train_dataset[0][0].unsqueeze(0)\n",
        "# Try forward\n",
        "out_size = model(test_x).size()\n",
        "print(f\"Out feature maps: {out_size} => out features: {out_size[1]*out_size[2]*out_size[3]}\")"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Out feature maps: torch.Size([1, 512, 4, 4]) => out features: 8192\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3KzLadIApu8"
      },
      "source": [
        "### Training Loop\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-LIlB5-37Jd"
      },
      "source": [
        "def train(epochs, dev, lr = 0.001):\n",
        "  try:\n",
        "    model = CNN()\n",
        "    model.to(dev)\n",
        "    print(model)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    history_loss = {\"train\": [], \"val\": [], \"test\": []}\n",
        "    history_accuracy = {\"train\": [], \"val\": [], \"test\": []}\n",
        "\n",
        "    for epoch in range(epoch):\n",
        "      sum_loss = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
        "      sum_accuracy = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
        "\n",
        "      for split in [\"train\", \"val\", \"test\"]:\n",
        "        for step,(anchor_img, positive_img, negative_img, anchor_label) in enumerate(loaders[split]):\n",
        "\n",
        "          anchor_img = anchor_img.to(device)\n",
        "          positive_img = positive_img.to(device)\n",
        "          negative_img = negative_img.to(device)\n",
        "\n",
        "          optimizer.zero_grad()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVA1Be_TBx5u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}